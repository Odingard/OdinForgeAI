STEP 1 â€” Add App-Layer AEV (Reasoning Only)
What you will add

A new exposure_type: "app_logic"

Minimal schema extensions in AEV models

Simulator logic for common app-logic risks:

IDOR/BOLA

Privilege boundary bypass

Mass assignment

Rate-limit / brute force feasibility (reasoning only)

Scoring tuned for app-layer impact

No crawling, no replay, no fuzzing

ðŸ“Œ Replit Task Checklist (copy/paste)

TASK A â€” Update AEV models

Open aev_engine/models.py

Replace it with the code below (or merge if you have extra fields)

from pydantic import BaseModel, Field
from typing import List, Dict, Optional, Literal

ExposureType = Literal[
    "cve",
    "misconfiguration",
    "behavior",
    "network_exposure",
    "privilege_escalation",
    "app_logic"
]

class ExposureInput(BaseModel):
    asset_id: str
    exposure_type: ExposureType
    description: str
    data: Dict = Field(default_factory=dict)

class SimulationResult(BaseModel):
    exploitable: bool
    confidence: float
    attack_path: List[str]
    impact: str
    recommended_fix: str
    score: float


TASK B â€” Add App-Layer Logic to simulator

Open aev_engine/simulator.py

Replace it with this version (keeps your existing types + adds app_logic)

from typing import Dict, List

class AdversarialSimulator:
    async def simulate(self, exposure) -> Dict:
        etype = exposure.exposure_type

        attack_path: List[str] = ["initial_enumeration", "adversarial_probe"]

        exploitable = False
        confidence = 0.35
        impact = "Low"
        recommended_fix = "Mitigate exposure manually."

        # ---- APP LOGIC (reasoning-only) ----
        if etype == "app_logic":
            # Expected data keys (any subset):
            # endpoint, method, auth_required, role_required, path_params, object_id_param,
            # ownership_enforced, rate_limit, sensitive_fields, accepts_user_input

            endpoint = str(exposure.data.get("endpoint", ""))
            method = str(exposure.data.get("method", "GET")).upper()
            path_params = exposure.data.get("path_params", []) or []
            object_id_param = exposure.data.get("object_id_param", "id")
            auth_required = bool(exposure.data.get("auth_required", True))
            ownership_enforced = exposure.data.get("ownership_enforced", None)  # True/False/None
            role_required = exposure.data.get("role_required", None)
            rate_limit = exposure.data.get("rate_limit", None)  # e.g. "none", "weak", "strong"
            sensitive_fields = exposure.data.get("sensitive_fields", []) or []
            accepts_user_input = bool(exposure.data.get("accepts_user_input", True))

            # IDOR/BOLA reasoning: object id in path or query and ownership unclear/false
            id_in_path = (object_id_param in path_params) or ("{id}" in endpoint) or ("/:id" in endpoint)
            if id_in_path and (ownership_enforced is False or ownership_enforced is None):
                exploitable = True
                confidence = 0.70 if auth_required else 0.85
                impact = "High"
                attack_path += ["object_id_manipulation", "unauthorized_object_access"]
                recommended_fix = (
                    "Enforce object-level authorization (BOLA/IDOR). "
                    "Validate ownership/permissions server-side for every object access."
                )

            # Privilege boundary bypass reasoning: role required but boundary enforcement unknown
            if role_required and ownership_enforced is None:
                exploitable = True
                confidence = max(confidence, 0.65)
                impact = "High"
                attack_path += ["role_boundary_probe", "privilege_bypass_attempt"]
                recommended_fix = (
                    "Enforce role-based access controls server-side. "
                    "Add authorization checks for privileged routes and verify scopes/claims."
                )

            # Mass assignment reasoning: accepts user input + sensitive fields present
            if accepts_user_input and sensitive_fields:
                exploitable = True
                confidence = max(confidence, 0.60)
                impact = "Medium"
                attack_path += ["parameter_tampering", "mass_assignment_attempt"]
                recommended_fix = (
                    "Implement allow-lists for writable fields. "
                    "Reject unexpected fields and validate payload schemas strictly."
                )

            # Rate limit reasoning (no execution): weak/none rate limits on auth endpoints
            if rate_limit in ["none", "weak"] and ("/login" in endpoint or "/auth" in endpoint):
                exploitable = True
                confidence = max(confidence, 0.60)
                impact = "Medium"
                attack_path += ["credential_stuffing_feasibility"]
                recommended_fix = (
                    "Add strong rate limiting, CAPTCHA/step-up auth, and lockout policies for auth endpoints."
                )

            # If no conditions triggered, return low-confidence non-exploitable guidance
            if not exploitable:
                attack_path += ["logic_validation_review"]
                recommended_fix = (
                    "Review endpoint authorization and business logic. "
                    "Add tests for BOLA/IDOR, role boundaries, and input validation."
                )
                confidence = 0.40
                impact = "Low"

            attack_path += ["validate_persistence"]
            return {
                "exploitable": exploitable,
                "confidence": float(confidence),
                "attack_path": attack_path,
                "impact": impact,
                "recommended_fix": recommended_fix,
            }

        # ---- EXISTING TYPES (keep minimal defaults) ----
        base_attack_path = ["attempt_exploit", "validate_persistence"]
        if etype in ["cve", "misconfiguration", "network_exposure", "privilege_escalation"]:
            exploitable = True
            confidence = 0.85
            impact = "High"
            attack_path += base_attack_path
            recommended_fix = "Apply patch or remove exposure."
        else:
            attack_path += ["validate_persistence"]
            recommended_fix = "Mitigate exposure manually."

        return {
            "exploitable": exploitable,
            "confidence": float(confidence),
            "attack_path": attack_path,
            "impact": impact,
            "recommended_fix": recommended_fix,
        }


TASK C â€” Tune scoring for app_logic

Open aev_engine/scoring.py

Replace with:

class ExposureScorer:
    def score(self, simulation: dict) -> float:
        confidence = float(simulation.get("confidence", 0.3))
        exploitable = bool(simulation.get("exploitable", False))
        impact = simulation.get("impact", "Low")

        impact_weight = {"High": 1.0, "Medium": 0.75, "Low": 0.45, "None": 0.1}
        w = impact_weight.get(impact, 0.35)

        base = confidence * w

        # Exploitability multiplier
        base *= 1.25 if exploitable else 0.35

        final = base * 100.0
        return round(min(final, 100.0), 2)


TASK D â€” Ensure evaluator returns score

Open aev_engine/evaluator.py

Ensure it sets score:

from .simulator import AdversarialSimulator
from .scoring import ExposureScorer

sim = AdversarialSimulator()
scorer = ExposureScorer()

class AEVEngine:
    async def evaluate(self, exposure):
        sim_result = await sim.simulate(exposure)
        sim_result["score"] = scorer.score(sim_result)
        return sim_result


TASK E â€” Add one test for app_logic

Create tests/test_app_logic_aev.py

import asyncio
from aev_engine.evaluator import AEVEngine
from aev_engine.models import ExposureInput

async def main():
    engine = AEVEngine()
    payload = ExposureInput(
        asset_id="app-1",
        exposure_type="app_logic",
        description="Possible IDOR on user resource",
        data={
            "endpoint": "/api/users/{id}",
            "method": "GET",
            "auth_required": True,
            "path_params": ["id"],
            "object_id_param": "id",
            "ownership_enforced": None,
            "role_required": None,
            "rate_limit": "strong",
            "sensitive_fields": [],
            "accepts_user_input": False
        },
    )
    res = await engine.evaluate(payload)
    print(res)

if __name__ == "__main__":
    asyncio.run(main())
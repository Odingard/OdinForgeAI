import type { AgentMemory, AgentResult, ExploitFindings } from "./types";
import { generateAdversaryPromptContext, adjustFindingsForProfile } from "./adversary-profile";
import { wrapAgentError } from "./error-classifier";
import { formatExecutionModeConstraints } from "./policy-context";
import { openai } from "./openai-client";
import { buildNetworkGroundTruth, buildReconGroundTruth } from "./scan-data-loader";

/**
 * ARCHITECTURAL CONSTRAINT: Plan-Only Agent
 *
 * This agent generates exploit PLANS (attack chains, techniques, recommendations)
 * but does NOT execute any real exploit actions. All outputs are analytical
 * assessments that describe potential exploitation paths.
 *
 * Actual action execution is gated by PolicyGuardian in the Orchestrator,
 * which validates planned actions against Rules of Engagement before they
 * are committed to final results.
 */

type ProgressCallback = (stage: string, progress: number, message: string) => void;

export async function runExploitAgent(
  memory: AgentMemory,
  onProgress?: ProgressCallback
): Promise<AgentResult<ExploitFindings>> {
  const startTime = Date.now();
  
  onProgress?.("exploit", 30, "Constructing exploit chains...");

  const reconContext = memory.recon
    ? `
Previous Recon Findings:
- Attack Surface: ${memory.recon.attackSurface.join(", ")}
- Entry Points: ${memory.recon.entryPoints.join(", ")}
- API Endpoints: ${memory.recon.apiEndpoints.join(", ")}
- Auth Mechanisms: ${memory.recon.authMechanisms.join(", ")}
- Technologies: ${memory.recon.technologies.join(", ")}
- Potential Vulnerabilities: ${memory.recon.potentialVulnerabilities.join(", ")}
`
    : "";

  const adversaryContext = memory.context.adversaryProfile 
    ? generateAdversaryPromptContext(memory.context.adversaryProfile)
    : "";
  
  const policyContext = memory.context.policyContext || "";
  const executionModeConstraints = formatExecutionModeConstraints(memory.context.executionMode || "safe");

  const systemPrompt = `You are the EXPLOIT AGENT, a specialized AI exploitation analysis system for OdinForge AI.

Your mission is to analyze the reconnaissance findings and determine:
1. Whether the target is exploitable in real-world conditions
2. Specific exploit chains that could be used (with MITRE ATT&CK techniques)
3. Relevant CVE references if applicable
4. Misconfigurations that could be abused

Think like an offensive security expert crafting exploitation strategies. Be realistic about success likelihood.
${adversaryContext}
${executionModeConstraints}
${policyContext}`;

  // Inject verified scan data (network vulns, auth issues, recon)
  const groundTruthContext = memory.groundTruth
    ? [buildNetworkGroundTruth(memory.groundTruth), buildReconGroundTruth(memory.groundTruth)].filter(Boolean).join("\n\n")
    : "";

  const userPrompt = `Analyze exploitability for this security exposure:

Asset ID: ${memory.context.assetId}
Exposure Type: ${memory.context.exposureType}
Priority: ${memory.context.priority}
Description: ${memory.context.description}
${reconContext}
${groundTruthContext ? `\n${groundTruthContext}\n` : ""}
Provide your exploitation analysis as a JSON object with this structure:
{
  "exploitable": boolean (true if realistically exploitable),
  "exploitChains": [
    {
      "name": "Name of the exploit chain",
      "technique": "MITRE ATT&CK technique ID (e.g., T1190)",
      "description": "Detailed description of how this exploit works",
      "success_likelihood": "high" | "medium" | "low"
    }
  ],
  "cveReferences": ["CVE-XXXX-XXXX if applicable"],
  "misconfigurations": ["list of exploitable misconfigurations"]
}`;

  try {
    onProgress?.("exploit", 35, "Analyzing CVE databases...");

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      response_format: { type: "json_object" },
      max_completion_tokens: 2048,
    });

    onProgress?.("exploit", 40, "Validating exploit feasibility...");

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new Error("No response from Exploit Agent");
    }

    const findings = JSON.parse(content) as ExploitFindings;
    
    const validatedFindings: ExploitFindings = {
      exploitable: Boolean(findings.exploitable),
      exploitChains: Array.isArray(findings.exploitChains)
        ? findings.exploitChains.map((chain) => ({
            name: String(chain.name || "Unknown"),
            technique: String(chain.technique || "T0000"),
            description: String(chain.description || ""),
            success_likelihood: validateLikelihood(chain.success_likelihood),
          }))
        : [],
      cveReferences: Array.isArray(findings.cveReferences) ? findings.cveReferences : [],
      misconfigurations: Array.isArray(findings.misconfigurations) ? findings.misconfigurations : [],
    };

    return {
      success: true,
      findings: validatedFindings,
      agentName: "Exploit Agent",
      processingTime: Date.now() - startTime,
    };
  } catch (error) {
    throw wrapAgentError("Exploit Agent", error);
  }
}

function validateLikelihood(likelihood: unknown): "high" | "medium" | "low" {
  const valid = ["high", "medium", "low"];
  return valid.includes(String(likelihood)) ? (likelihood as "high" | "medium" | "low") : "medium";
}
